{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> API to get structured output from a string using different LLM providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from litellm import completion\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def structured_output(model:str, # Model name, see examples here or LiteLLM docs for complete list\n",
    "                      system_prompt:str, # Instructions for LLM to process the input string\n",
    "                      user_prompt:str, # Input string that will be processed\n",
    "                      response_format:BaseModel # User-defined Pydantic model to define output \n",
    "                     ) -> BaseModel :\n",
    "    response = completion(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        response_format=response_format\n",
    "    )\n",
    "    return response_format.model_validate_json(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"azure/gpt-4o-2024-08-06\"\n",
    "system_prompt = \"Extract the event information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines the output response format that we want\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Alice and Bob are going to Carmen's Birtday party on 22nd March 2025\"\n",
    "# Note that the word \"Birthday\" is spelt incorrectly on purpose for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': \"Carmen's Birthday Party\",\n",
       " 'date': '22nd March 2025',\n",
       " 'participants': ['Alice', 'Bob']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "r = structured_output(model=model,\n",
    "                      system_prompt=system_prompt,\n",
    "                      user_prompt=user_prompt,\n",
    "                      response_format=CalendarEvent, #Note this is the class name (without the `()`)\n",
    "                 )\n",
    "\n",
    "r.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
